{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7ptwarT6J2yo",
      "metadata": {
        "id": "7ptwarT6J2yo"
      },
      "source": [
        "# DIA-NN QC Plots (Colab)\n",
        "\n",
        "This notebook mirrors `diann-stats.py` so you can generate DIA-NN QC PDFs directly in Colab:\n",
        "1. Install dependencies and load the helper functions.\n",
        "2. Provide the DIA-NN `.parquet` export (upload or mount Drive).\n",
        "3. Run `run_diann_stats` to create `<file>_runs.pdf` and `<file>_trends.pdf`.\n",
        "4. Download the PDFs from the left sidebar (`Files` panel).\n",
        "\n",
        "Adjust plot visibility through `plot_configs` if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5wj4RPC5J2yr",
      "metadata": {
        "id": "5wj4RPC5J2yr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q polars matplotlib numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "biyKCKRPJ2ys",
      "metadata": {
        "id": "biyKCKRPJ2ys"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import polars as pl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "HIST_COLOR = \"steelblue\"\n",
        "CMAP = \"bone_r\"\n",
        "\n",
        "plot_configs = {\n",
        "    \"Identified_MS1_TIC\": {\"function\": \"plot_identified_ms1_tic\", \"enabled\": True},\n",
        "    \"RT_histogram\": {\"function\": \"plot_rt_histogram\", \"enabled\": True},\n",
        "    \"MZ_histogram\": {\"function\": \"plot_mz_histogram\", \"enabled\": True},\n",
        "    \"Charge_histogram\": {\"function\": \"plot_charge_histogram\", \"enabled\": True},\n",
        "    \"Precursors_per_protein\": {\"function\": \"plot_precursors_per_protein\", \"enabled\": True},\n",
        "    \"MS1_corr_histogram\": {\"function\": \"plot_ms1_corr_histogram\", \"enabled\": True},\n",
        "    \"RT_vs_iRT\": {\"function\": \"plot_rt_vs_irt\", \"enabled\": True},\n",
        "    \"RT_vs_Predicted_RT\": {\"function\": \"plot_rt_vs_predicted_rt\", \"enabled\": True},\n",
        "    \"MZ_vs_RT\": {\"function\": \"plot_mz_vs_rt\", \"enabled\": True},\n",
        "    \"IM_vs_Predicted_IM\": {\"function\": \"plot_im_vs_predicted_im\", \"enabled\": True},\n",
        "    \"IM_vs_MZ\": {\"function\": \"plot_im_vs_mz\", \"enabled\": True},\n",
        "    \"Normalization_vs_RT\": {\"function\": \"plot_normalization_vs_rt\", \"enabled\": True},\n",
        "    \"MZ_delta_vs_RT\": {\"function\": \"plot_mz_delta_vs_rt\", \"enabled\": True},\n",
        "    \"MZ_delta_vs_MZ\": {\"function\": \"plot_mz_delta_vs_mz\", \"enabled\": True},\n",
        "    \"MS2_delta_vs_RT\": {\"function\": \"plot_ms2_delta_vs_rt\", \"enabled\": True},\n",
        "    \"MS2_delta_vs_MZ\": {\"function\": \"plot_ms2_delta_vs_mz\", \"enabled\": True},\n",
        "    \"FWHM_histogram\": {\"function\": \"plot_fwhm_histogram\", \"enabled\": True},\n",
        "    \"FWHM_vs_RT\": {\"function\": \"plot_fwhm_vs_rt\", \"enabled\": True},\n",
        "    \"QValue_histogram\": {\"function\": \"plot_qvalue_histogram\", \"enabled\": False},\n",
        "    \"IRT_proportion\": {\"function\": \"plot_irt_proportion\", \"enabled\": True},\n",
        "    \"MZ_proportion_global\": {\"function\": \"plot_mz_proportion_global\", \"enabled\": True},\n",
        "}\n",
        "\n",
        "run_to_proportions = None\n",
        "irt_bin_centers = None\n",
        "mz_bin_centers = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "KaupX7ljJ2ys",
      "metadata": {
        "id": "KaupX7ljJ2ys"
      },
      "outputs": [],
      "source": [
        "# Plotting helpers\n",
        "def plot_rt_histogram(df, run, ax):\n",
        "    try:\n",
        "        ax.hist(df[\"RT\"], bins=50, color=HIST_COLOR, rwidth=0.9)\n",
        "        ax.set_title(f\"RT, n = {df.height}\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_mz_histogram(df, run, ax):\n",
        "    try:\n",
        "        ax.hist(df[\"Precursor.Mz\"], bins=50, color=HIST_COLOR, rwidth=0.9)\n",
        "        ax.set_title(f\"m/z, n = {df.height}\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_charge_histogram(df, run, ax):\n",
        "    try:\n",
        "        charges = df[\"Precursor.Charge\"].unique().sort()\n",
        "        bins = np.arange(1, charges.max() + 1.5) - 0.5\n",
        "        ax.hist(df[\"Precursor.Charge\"], bins=bins, color=HIST_COLOR, rwidth=0.9)\n",
        "        ax.set_title(\"Precursor Charge\")\n",
        "        ax.set_xticks(bins + 0.5)\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_ms1_corr_histogram(df, run, ax):\n",
        "    try:\n",
        "        ax.hist(df[\"Ms1.Profile.Corr\"], bins=50, color=HIST_COLOR, rwidth=0.9)\n",
        "        ax.set_title(\"MS1 Profile Correlation\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_rt_vs_irt(df, run, ax):\n",
        "    try:\n",
        "        irt_min = df[\"iRT\"].quantile(0.01)\n",
        "        irt_max = df[\"iRT\"].quantile(0.99)\n",
        "        frac_df = df.filter((pl.col(\"iRT\") >= irt_min) & (pl.col(\"iRT\") <= irt_max))\n",
        "        H, xedges, yedges = np.histogram2d(frac_df[\"iRT\"], frac_df[\"RT\"], bins=256)\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 99)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"RT vs library RT\")\n",
        "        ax.set_xlabel(\"library RT\")\n",
        "        ax.set_ylabel(\"RT\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_rt_vs_predicted_rt(df, run, ax):\n",
        "    try:\n",
        "        H, xedges, yedges = np.histogram2d(df[\"Predicted.RT\"], df[\"RT\"], bins=256)\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 99)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"RT vs Predicted.RT\")\n",
        "        ax.set_xlabel(\"Predicted.RT\")\n",
        "        ax.set_ylabel(\"RT\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_im_vs_predicted_im(df, run, ax):\n",
        "    try:\n",
        "        H, xedges, yedges = np.histogram2d(df[\"Predicted.IM\"], df[\"IM\"], bins=256)\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 99)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"IM vs Predicted.IM\")\n",
        "        ax.set_xlabel(\"Predicted.IM\")\n",
        "        ax.set_ylabel(\"IM\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_mz_vs_rt(df, run, ax):\n",
        "    try:\n",
        "        H, xedges, yedges = np.histogram2d(df[\"RT\"], df[\"Precursor.Mz\"], bins=256)\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 99)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"m/z vs RT\")\n",
        "        ax.set_xlabel(\"RT\")\n",
        "        ax.set_ylabel(\"m/z\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_im_vs_mz(df, run, ax):\n",
        "    try:\n",
        "        H, xedges, yedges = np.histogram2d(df[\"Precursor.Mz\"], df[\"IM\"], bins=256)\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 99)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"IM vs m/z\")\n",
        "        ax.set_xlabel(\"m/z\")\n",
        "        ax.set_ylabel(\"IM\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_normalization_vs_rt(df, run, ax):\n",
        "    try:\n",
        "        H, xedges, yedges = np.histogram2d(\n",
        "            df[\"RT\"],\n",
        "            df[\"Normalisation.Factor\"],\n",
        "            bins=256,\n",
        "            range=[[df[\"RT\"].min(), df[\"RT\"].max()], [0.0, df[\"Normalisation.Factor\"].max() * 1.05]],\n",
        "        )\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 1)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"Normalisation Factor vs RT\")\n",
        "        ax.set_xlabel(\"RT\")\n",
        "        ax.set_ylabel(\"Normalization Factor\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_fwhm_vs_rt(df, run, ax):\n",
        "    try:\n",
        "        H, xedges, yedges = np.histogram2d(\n",
        "            df[\"RT\"],\n",
        "            df[\"FWHM\"],\n",
        "            bins=256,\n",
        "            range=[[df[\"RT\"].min(), df[\"RT\"].max()], [0.0, df[\"FWHM\"].max()]],\n",
        "        )\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 99)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"Peak FWHM vs RT\")\n",
        "        ax.set_xlabel(\"RT\")\n",
        "        ax.set_ylabel(\"FWHM\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_mz_delta_vs_rt(df, run, ax):\n",
        "    try:\n",
        "        ms1_present = (\n",
        "            df.filter(pl.col(\"Ms1.Apex.Area\") > 0.01)\n",
        "            .filter(pl.col(\"Ms1.Profile.Corr\") > 0.5)\n",
        "            .filter(pl.col(\"Ms1.Apex.Mz.Delta\") != 0.0)\n",
        "        )\n",
        "        ms1_present = ms1_present.with_columns(\n",
        "            (1000000.0 * (pl.col(\"Ms1.Apex.Mz.Delta\") / pl.col(\"Precursor.Mz\"))).alias(\"Mass_Delta_Ratio\")\n",
        "        )\n",
        "        H, xedges, yedges = np.histogram2d(ms1_present[\"RT\"], ms1_present[\"Mass_Delta_Ratio\"], bins=256)\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 99)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"MS1 m/z delta (ppm) vs RT\")\n",
        "        ax.set_xlabel(\"RT\")\n",
        "        ax.set_ylabel(\"MS1 m/z delta (ppm)\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_mz_delta_vs_mz(df, run, ax):\n",
        "    try:\n",
        "        ms1_present = (\n",
        "            df.filter(pl.col(\"Ms1.Apex.Area\") > 0.01)\n",
        "            .filter(pl.col(\"Ms1.Profile.Corr\") > 0.5)\n",
        "            .filter(pl.col(\"Ms1.Apex.Mz.Delta\") != 0.0)\n",
        "        )\n",
        "        ms1_present = ms1_present.with_columns(\n",
        "            (1000000.0 * (pl.col(\"Ms1.Apex.Mz.Delta\") / pl.col(\"Precursor.Mz\"))).alias(\"Mass_Delta_Ratio\")\n",
        "        )\n",
        "        H, xedges, yedges = np.histogram2d(ms1_present[\"Precursor.Mz\"], ms1_present[\"Mass_Delta_Ratio\"], bins=256)\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 99)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"MS1 m/z delta (ppm) vs m/z\")\n",
        "        ax.set_xlabel(\"m/z\")\n",
        "        ax.set_ylabel(\"MS1 m/z delta (ppm)\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_ms2_delta_vs_rt(df, run, ax):\n",
        "    try:\n",
        "        selected = df.filter(pl.col(\"Evidence\") > 3.0)\n",
        "        selected = selected.with_columns(\n",
        "            (1000000.0 * (pl.col(\"Best.Fr.Mz.Delta\") / pl.col(\"Best.Fr.Mz\"))).alias(\"Mass_Delta_Ratio\")\n",
        "        )\n",
        "        H, xedges, yedges = np.histogram2d(selected[\"RT\"], selected[\"Mass_Delta_Ratio\"], bins=256)\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 99)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"MS2 m/z delta (ppm) vs RT\")\n",
        "        ax.set_xlabel(\"RT\")\n",
        "        ax.set_ylabel(\"MS2 m/z delta (ppm)\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_ms2_delta_vs_mz(df, run, ax):\n",
        "    try:\n",
        "        selected = df.filter(pl.col(\"Evidence\") > 3.0)\n",
        "        selected = selected.with_columns(\n",
        "            (1000000.0 * (pl.col(\"Best.Fr.Mz.Delta\") / pl.col(\"Best.Fr.Mz\"))).alias(\"Mass_Delta_Ratio\")\n",
        "        )\n",
        "        H, xedges, yedges = np.histogram2d(selected[\"Best.Fr.Mz\"], selected[\"Mass_Delta_Ratio\"], bins=256)\n",
        "        H = H.T\n",
        "        vmax = np.percentile(H[H > 0], 99)\n",
        "        ax.pcolorfast(xedges, yedges, H, cmap=CMAP, vmin=0, vmax=vmax)\n",
        "        ax.set_title(\"MS2 m/z delta (ppm) vs m/z\")\n",
        "        ax.set_xlabel(\"m/z\")\n",
        "        ax.set_ylabel(\"MS2 m/z delta (ppm)\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_identified_ms1_tic(df, run, ax):\n",
        "    try:\n",
        "        rt_min, rt_max = df[\"RT\"].min(), df[\"RT\"].max()\n",
        "        rt_bins = np.linspace(rt_min, rt_max, 128 + 1)\n",
        "        binned = df.with_columns(pl.col(\"RT\").cut(rt_bins).alias(\"bin\"))\n",
        "        rt_area = binned.group_by(\"bin\").agg(pl.sum(\"Ms1.Apex.Area\"))\n",
        "        rt_area = rt_area.unique(subset=[\"bin\"]).sort(\"bin\")\n",
        "        ax.bar(rt_area[\"bin\"], rt_area[\"Ms1.Apex.Area\"], color=HIST_COLOR)\n",
        "        ax.set_title(\"Identified MS1 TIC\")\n",
        "        ax.set_xlabel(\"RT\")\n",
        "        ax.set_ylabel(\"Total MS1 signal at apex\")\n",
        "        ax.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_precursors_per_protein(df, run, ax):\n",
        "    try:\n",
        "        sig_proteins = df.filter(pl.col(\"PG.Q.Value\") <= 0.01)\n",
        "        pr_per_prot = (\n",
        "            sig_proteins.group_by(\"Protein.Group\")\n",
        "            .agg(pl.count(\"Precursor.Id\"))\n",
        "            .get_column(\"Precursor.Id\")\n",
        "            .value_counts()\n",
        "            .sort(\"Precursor.Id\")\n",
        "        )\n",
        "        max_count = pr_per_prot[\"Precursor.Id\"].max()\n",
        "        x_values = list(range(1, max_count + 1))\n",
        "        y_values = [0] * max_count\n",
        "        for row in pr_per_prot.iter_rows():\n",
        "            y_values[row[0] - 1] = row[1]\n",
        "        ax.bar(x_values, y_values, color=HIST_COLOR)\n",
        "        num_proteins = sig_proteins.select(pl.col(\"Protein.Group\").n_unique()).item()\n",
        "        ax.set_title(f\"Precursors per protein group, n = {num_proteins}\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_fwhm_histogram(df, run, ax):\n",
        "    try:\n",
        "        ax.hist(df[\"FWHM\"], bins=50, color=HIST_COLOR, rwidth=0.9, range=[0.0, df[\"FWHM\"].max()])\n",
        "        ax.set_title(\"Peak Width (FWHM)\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_qvalue_histogram(df, run, ax):\n",
        "    try:\n",
        "        ax.hist(df[\"Q.Value\"], bins=50, color=HIST_COLOR, rwidth=0.9)\n",
        "        ax.set_title(\"Q-Value\")\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_irt_proportion(df, run, ax):\n",
        "    try:\n",
        "        global run_to_proportions, irt_bin_centers\n",
        "        irt_proportions = run_to_proportions[run][\"irt_proportions\"]\n",
        "        proportions = irt_proportions[\"proportion\"].to_numpy()\n",
        "        ax.bar(range(len(proportions)), proportions, color=HIST_COLOR)\n",
        "        ax.set_title(\"ID rate per library RT Bin\")\n",
        "        ax.set_xlabel(\"library RT\")\n",
        "        ax.set_ylabel(\"Proportion\")\n",
        "        ax.set_ylim(0, 1)\n",
        "        tick_positions = np.arange(0, 50, 8)\n",
        "        tick_labels = [f\"{irt_bin_centers[i]:.1f}\" for i in tick_positions]\n",
        "        ax.set_xticks(tick_positions)\n",
        "        ax.set_xticklabels(tick_labels)\n",
        "    except Exception as exc:\n",
        "        print(exc)\n",
        "\n",
        "def plot_mz_proportion_global(df, run, ax):\n",
        "    try:\n",
        "        global run_to_proportions, mz_bin_centers\n",
        "        mz_proportions = run_to_proportions[run][\"mz_proportions\"]\n",
        "        proportions = mz_proportions[\"proportion\"].to_numpy()\n",
        "        ax.bar(range(len(proportions)), proportions, color=HIST_COLOR)\n",
        "        ax.set_title(\"ID rate per m/z Bin\")\n",
        "        ax.set_xlabel(\"m/z\")\n",
        "        ax.set_ylabel(\"Proportion\")\n",
        "        ax.set_ylim(0, 1)\n",
        "\n",
        "        cap_mz = max(mz_bin_centers)\n",
        "        min_mz = np.floor(min(mz_bin_centers) / 100) * 100\n",
        "        max_mz = np.ceil(cap_mz / 100) * 100\n",
        "        step_size = 100 if max_mz - min_mz <= 1000 else 200\n",
        "        mz_ticks = np.arange(min_mz, max_mz + step_size, step_size)\n",
        "        flt = []\n",
        "        for tick in mz_ticks:\n",
        "            flt.append(tick <= cap_mz + 20)\n",
        "        mz_ticks = mz_ticks[flt]\n",
        "        tick_positions = []\n",
        "        tick_labels = []\n",
        "        for mz_val in mz_ticks:\n",
        "            bin_idx = np.argmin(np.abs(mz_bin_centers - mz_val))\n",
        "            if bin_idx not in tick_positions:\n",
        "                tick_positions.append(bin_idx)\n",
        "                tick_labels.append(f\"{int(mz_val)}\")\n",
        "        ax.set_xticks(tick_positions)\n",
        "        ax.set_xticklabels(tick_labels)\n",
        "    except Exception as exc:\n",
        "        print(exc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "44s3sB8lJ2yt",
      "metadata": {
        "id": "44s3sB8lJ2yt"
      },
      "outputs": [],
      "source": [
        "def plot_page(df, run):\n",
        "    '''Generate a dynamic grid of plots for a single acquisition.'''\n",
        "    enabled_plots = [plot for plot in plot_configs if plot_configs[plot][\"enabled\"]]\n",
        "    total_plots = len(enabled_plots)\n",
        "    cols = 4\n",
        "    rows = (total_plots + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(20, 5 * rows))\n",
        "    axes = axes.flat if total_plots > 1 else [axes]\n",
        "    for ax, plot in zip(axes, enabled_plots):\n",
        "        globals()[plot_configs[plot][\"function\"]](df, run, ax)\n",
        "    for ax in axes[total_plots:]:\n",
        "        ax.axis(\"off\")\n",
        "    fig.suptitle(f\"{run}\", fontsize=16, y=0.98)\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    return fig\n",
        "\n",
        "def compute_summary_metrics(df):\n",
        "    '''Compute summary metrics for each run, ordered by Run.Index if available.'''\n",
        "    if \"Run.Index\" in df.columns:\n",
        "        df_sorted = df.sort(\"Run.Index\")\n",
        "        run_order = df.select([\"Run\", \"Run.Index\"]).unique().sort(by=\"Run.Index\")\n",
        "        runs = run_order[\"Run\"].to_list()\n",
        "    else:\n",
        "        df_sorted = df\n",
        "        runs = df.select(\"Run\").unique(maintain_order=True).to_series().to_list()\n",
        "    metrics_df = df_sorted.group_by(\"Run\", maintain_order=True).agg([\n",
        "        pl.len().alias(\"num_precursors\"),\n",
        "        (pl.col(\"Protein.Group\").filter(pl.col(\"PG.Q.Value\") <= 0.01).n_unique()).alias(\"num_proteins\"),\n",
        "        pl.col(\"Ms1.Apex.Area\").sum().alias(\"total_ms1_tic\"),\n",
        "    ])\n",
        "    metrics = {col: metrics_df[col].to_list() for col in metrics_df.columns if col != \"Run\"}\n",
        "    return runs, metrics\n",
        "\n",
        "def plot_summary(runs, metrics, pdf):\n",
        "    metric_display_names = {\n",
        "        \"num_precursors\": \"Number of Identified Precursors\",\n",
        "        \"num_proteins\": \"Number of Identified Protein Groups\",\n",
        "        \"total_ms1_tic\": \"Total MS1 Apex Signal\",\n",
        "    }\n",
        "    total_runs = len(runs)\n",
        "    fig_width = 10\n",
        "    longest_run_label = max([len(run) for run in runs]) if runs else 1\n",
        "    if total_runs > 1:\n",
        "        font_size = 14\n",
        "        font_size = min(font_size, (fig_width / (total_runs - 1)) * 72 * 0.35)\n",
        "        font_size = min(font_size, (fig_width * 72) / (1.5 * longest_run_label))\n",
        "    else:\n",
        "        font_size = 5\n",
        "    for metric_name, metric_values in metrics.items():\n",
        "        fig, ax = plt.subplots(figsize=(fig_width, 6), constrained_layout=True)\n",
        "        ax.plot(range(total_runs), metric_values, \"o-\", color=\"darkblue\")\n",
        "        display_name = metric_display_names.get(metric_name, metric_name)\n",
        "        ax.set_title(f\"{display_name} vs Run Order\")\n",
        "        ax.set_xlabel(\"Run\")\n",
        "        ax.set_ylabel(display_name)\n",
        "        ax.grid(True, linestyle=\"--\", alpha=0.7)\n",
        "        ax.set_xticks(range(total_runs))\n",
        "        ax.set_xticklabels(runs, rotation=45, ha=\"right\", fontsize=font_size)\n",
        "        pdf.savefig(fig)\n",
        "        plt.close(fig)\n",
        "\n",
        "def run_diann_stats(parquet_file):\n",
        "    '''Generate per-run and trend PDFs from a DIA-NN parquet export.'''\n",
        "    global run_to_proportions, irt_bin_centers, mz_bin_centers\n",
        "    run_to_proportions = None\n",
        "    irt_bin_centers = None\n",
        "    mz_bin_centers = None\n",
        "\n",
        "    df = pl.read_parquet(parquet_file).filter(pl.col(\"Q.Value\") <= 0.01)\n",
        "    precursor_run_counts = df.group_by(\"Precursor.Id\").agg(pl.col(\"Run\").n_unique().alias(\"run_count\"))\n",
        "    max_run_count = precursor_run_counts[\"run_count\"].max()\n",
        "    threshold = int(np.ceil(0.99 * max_run_count))\n",
        "    selected_precursors = (\n",
        "        precursor_run_counts.filter(pl.col(\"run_count\") >= threshold)[\"Precursor.Id\"].to_list()\n",
        "    )\n",
        "    global_precursors = df.filter(pl.col(\"Global.Q.Value\") <= 0.01)[\"Precursor.Id\"].to_list()\n",
        "    if \"Run.Index\" in df.columns:\n",
        "        df_sorted = df.sort(\"Run.Index\")\n",
        "        run_order = df.select([\"Run\", \"Run.Index\"]).unique().sort(by=\"Run.Index\")\n",
        "        runs = run_order[\"Run\"].to_list()\n",
        "    else:\n",
        "        df_sorted = df\n",
        "        runs = df.select(\"Run\").unique(maintain_order=True).to_series().to_list()\n",
        "    runs, metrics = compute_summary_metrics(df)\n",
        "\n",
        "    selected_df = df_sorted.filter(pl.col(\"Precursor.Id\").is_in(selected_precursors))\n",
        "    agg_list = [\n",
        "        pl.col(\"RT\").quantile(0.25).alias(\"RT_Q1\"),\n",
        "        pl.col(\"RT\").quantile(0.5).alias(\"RT_median\"),\n",
        "        pl.col(\"RT\").quantile(0.75).alias(\"RT_Q3\"),\n",
        "    ]\n",
        "    if df[\"IM\"].max() > 0.5:\n",
        "        agg_list.extend([\n",
        "            pl.col(\"IM\").quantile(0.25).alias(\"IM_Q1\"),\n",
        "            pl.col(\"IM\").quantile(0.5).alias(\"IM_median\"),\n",
        "            pl.col(\"IM\").quantile(0.75).alias(\"IM_Q3\"),\n",
        "        ])\n",
        "    agg_list.extend([\n",
        "        pl.col(\"FWHM\").quantile(0.25).alias(\"FWHM_Q1\"),\n",
        "        pl.col(\"FWHM\").quantile(0.5).alias(\"FWHM_median\"),\n",
        "        pl.col(\"FWHM\").quantile(0.75).alias(\"FWHM_Q3\"),\n",
        "    ])\n",
        "    stats_df = selected_df.group_by(\"Run\", maintain_order=True).agg(agg_list)\n",
        "\n",
        "    frac_df = df.filter(pl.col(\"Precursor.Id\").is_in(global_precursors))\n",
        "    irt_min = frac_df[\"iRT\"].quantile(0.01) - 0.00001\n",
        "    irt_max = frac_df[\"iRT\"].quantile(0.99) + 0.00001\n",
        "    frac_df = frac_df.filter(pl.col(\"Precursor.Id\").is_in(global_precursors)).filter(\n",
        "        (pl.col(\"iRT\") >= irt_min) & (pl.col(\"iRT\") <= irt_max)\n",
        "    )\n",
        "    mz_min, mz_max = frac_df[\"Precursor.Mz\"].min() - 0.00001, frac_df[\"Precursor.Mz\"].max() + 0.00001\n",
        "    irt_bins = np.linspace(irt_min, irt_max, 51)\n",
        "    mz_bins = np.linspace(mz_min, mz_max, 51)\n",
        "\n",
        "    precursor_info = (\n",
        "        frac_df.group_by(\"Precursor.Id\")\n",
        "        .agg([\n",
        "            pl.col(\"iRT\").first().alias(\"iRT\"),\n",
        "            pl.col(\"Precursor.Mz\").first().alias(\"MZ\"),\n",
        "        ])\n",
        "        .with_columns(\n",
        "            pl.col(\"iRT\").cut(irt_bins, labels=[str(i) for i in range(52)]).alias(\"IRT_bin\"),\n",
        "            pl.col(\"MZ\").cut(mz_bins, labels=[str(i) for i in range(52)]).alias(\"MZ_bin\"),\n",
        "        )\n",
        "    )\n",
        "    precursor_info = precursor_info.filter(pl.col(\"Precursor.Id\").is_in(global_precursors))\n",
        "    total_irt_counts = (\n",
        "        precursor_info.group_by(\"IRT_bin\")\n",
        "        .agg(pl.len().alias(\"total_count\"))\n",
        "        .sort(\"IRT_bin\")\n",
        "        .with_columns(pl.col(\"IRT_bin\").cast(pl.Utf8))\n",
        "        .with_columns(pl.col(\"total_count\").replace(0, 1))\n",
        "    )\n",
        "    total_mz_counts = (\n",
        "        precursor_info.group_by(\"MZ_bin\")\n",
        "        .agg(pl.len().alias(\"total_count\"))\n",
        "        .sort(\"MZ_bin\")\n",
        "        .with_columns(pl.col(\"MZ_bin\").cast(pl.Utf8))\n",
        "        .with_columns(pl.col(\"total_count\").replace(0, 1))\n",
        "    )\n",
        "\n",
        "    run_to_proportions = {}\n",
        "    for run in runs:\n",
        "        run_data = frac_df.filter(pl.col(\"Run\") == run)\n",
        "        run_data = run_data.join(precursor_info.select([\"Precursor.Id\", \"IRT_bin\", \"MZ_bin\"]), on=\"Precursor.Id\")\n",
        "\n",
        "        irt_counts = run_data.group_by(\"IRT_bin\").agg(pl.len().alias(\"count\")).sort(\"IRT_bin\").with_columns(\n",
        "            pl.col(\"IRT_bin\").cast(pl.Utf8)\n",
        "        )\n",
        "        all_irt_bins = pl.DataFrame({\"IRT_bin\": [str(i) for i in range(1, 51)]})\n",
        "        irt_counts = all_irt_bins.join(irt_counts, on=\"IRT_bin\", how=\"left\").fill_null(0)\n",
        "        irt_proportions = irt_counts.join(total_irt_counts, on=\"IRT_bin\").with_columns(\n",
        "            (pl.col(\"count\") / pl.col(\"total_count\")).alias(\"proportion\")\n",
        "        )\n",
        "\n",
        "        mz_counts = run_data.group_by(\"MZ_bin\").agg(pl.len().alias(\"count\")).sort(\"MZ_bin\").with_columns(\n",
        "            pl.col(\"MZ_bin\").cast(pl.Utf8)\n",
        "        )\n",
        "        all_mz_bins = pl.DataFrame({\"MZ_bin\": [str(i) for i in range(1, 51)]})\n",
        "        mz_counts = all_mz_bins.join(mz_counts, on=\"MZ_bin\", how=\"left\").fill_null(0)\n",
        "        mz_proportions = mz_counts.join(total_mz_counts, on=\"MZ_bin\").with_columns(\n",
        "            (pl.col(\"count\") / pl.col(\"total_count\")).alias(\"proportion\")\n",
        "        )\n",
        "        run_to_proportions[run] = {\"irt_proportions\": irt_proportions, \"mz_proportions\": mz_proportions}\n",
        "\n",
        "    irt_bin_centers = (irt_bins[:-1] + irt_bins[1:]) / 2\n",
        "    mz_bin_centers = (mz_bins[:-1] + mz_bins[1:]) / 2\n",
        "\n",
        "    runs_pdf = f\"{parquet_file.rsplit('.', 1)[0]}_runs.pdf\"\n",
        "    with PdfPages(runs_pdf) as pdf:\n",
        "        for run in runs:\n",
        "            run_data = df.filter(pl.col(\"Run\") == run)\n",
        "            fig = plot_page(run_data, run)\n",
        "            pdf.savefig(fig)\n",
        "            plt.close(fig)\n",
        "    print(f\"Saved per-run plots to {runs_pdf}\")\n",
        "\n",
        "    trends_pdf = f\"{parquet_file.rsplit('.', 1)[0]}_trends.pdf\"\n",
        "    with PdfPages(trends_pdf) as pdf:\n",
        "        plot_summary(runs, metrics, pdf)\n",
        "        metrics_to_plot = [\"RT\"]\n",
        "        if df[\"IM\"].max() > 0.5:\n",
        "            metrics_to_plot.append(\"IM\")\n",
        "        metrics_to_plot.append(\"FWHM\")\n",
        "        total_runs = len(runs)\n",
        "        fig_width = 10\n",
        "        longest_run_label = max([len(run) for run in runs]) if runs else 1\n",
        "        if total_runs > 1:\n",
        "            font_size = 14\n",
        "            font_size = min(font_size, (fig_width / (total_runs - 1)) * 72 * 0.35)\n",
        "            font_size = min(font_size, (fig_width * 72) / (1.5 * longest_run_label))\n",
        "        else:\n",
        "            font_size = 5\n",
        "        for metric in metrics_to_plot:\n",
        "            fig, ax = plt.subplots(figsize=(fig_width, 6), constrained_layout=True)\n",
        "            ax.plot(range(total_runs), stats_df[f\"{metric}_Q3\"], label=\"Q3\", color=\"steelblue\")\n",
        "            ax.plot(range(total_runs), stats_df[f\"{metric}_median\"], label=\"Median\", color=\"black\")\n",
        "            ax.plot(range(total_runs), stats_df[f\"{metric}_Q1\"], label=\"Q1\", color=\"seagreen\")\n",
        "            ax.set_title(f\"{metric} Distribution for Consistently Identified Precursors\")\n",
        "            ax.set_xlabel(\"Run\")\n",
        "            ax.set_ylabel(metric)\n",
        "            ax.legend()\n",
        "            ax.grid(True, linestyle=\"--\", alpha=0.7)\n",
        "            ax.set_xticks(range(total_runs))\n",
        "            ax.set_xticklabels(runs, rotation=45, ha=\"right\", fontsize=font_size)\n",
        "            pdf.savefig(fig)\n",
        "            plt.close(fig)\n",
        "    print(f\"Saved trend plots to {trends_pdf}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K3wZM7JhJ2yt",
      "metadata": {
        "id": "K3wZM7JhJ2yt"
      },
      "source": [
        "## Upload or reference the DIA-NN parquet file\n",
        "\n",
        "Use `upload_parquet()` below to pick a file from your laptop, or mount Drive and set `PARQUET_PATH` to the file location inside `/content`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "SzD4nJWiJ2yt",
      "metadata": {
        "id": "SzD4nJWiJ2yt"
      },
      "outputs": [],
      "source": [
        "from tkinter import Tk, filedialog\n",
        "\n",
        "def upload_parquet():\n",
        "    root = Tk()\n",
        "    root.withdraw()\n",
        "    filename = filedialog.askopenfilename(\n",
        "        title=\"Pick DIA-NN parquet export\",\n",
        "        filetypes=[(\"Parquet files\", \"*.parquet\"), (\"All files\", \"*.*\")]\n",
        "    )\n",
        "    if not filename:\n",
        "        raise ValueError(\"No file selected.\")\n",
        "    print(f\"Selected file: {filename}\")\n",
        "    return filename\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d8mY5BhKJ2yt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "d8mY5BhKJ2yt",
        "outputId": "beaee159-5c76-4155-a93f-8887009aafa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected file: /Volumes/DataArchive/Current_Data/savannah_nov_2025/out/report.parquet\n",
            "Saved per-run plots to /Volumes/DataArchive/Current_Data/savannah_nov_2025/out/report_runs.pdf\n",
            "Saved trend plots to /Volumes/DataArchive/Current_Data/savannah_nov_2025/out/report_trends.pdf\n"
          ]
        }
      ],
      "source": [
        "PARQUET_PATH = upload_parquet()\n",
        "\n",
        "if not PARQUET_PATH:\n",
        "    raise ValueError(\"Set PARQUET_PATH or call upload_parquet() before running the pipeline.\")\n",
        "\n",
        "run_diann_stats(PARQUET_PATH)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
